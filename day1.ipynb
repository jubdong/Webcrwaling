{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 라이브러리 호출\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import pyautogui as pg\n",
    "from selenium import webdriver\n",
    "\n",
    "#warning 삭제방법\n",
    "import urllib3\n",
    "requests.packages.urllib3.disable_warnings(requests.packages.urllib3.exceptions.InsecureRequestWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# naver 웹서버에 HTTP 요청 \n",
    "res = requests.get('https://www.naver.com', verify=False) # 보안상의 이유로 verify=False 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#서버가 보낸 정보를 텍스트로 확인\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EC%95%84%EC%9D%B4%EC%9C%A0'\n",
    "res = requests.get(url, verify=False)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://search.naver.com/search.naver?where=nexearch&sm=top_hty&fbm=0&ie=utf8&query=%EC%95%84%EC%9D%B4%EC%9C%A0'\n",
    "#url 파라미터로 분해화하여 requests\n",
    "# ?다음부터 파라미터\n",
    "#개발자도구 - Network(filter:doc) - payload에서 확인 가능\n",
    "\n",
    "url = 'https://search.naver.com/search.naver'\n",
    "search_key = '아이유'\n",
    "para = {\n",
    "    'where': 'nexearch',\n",
    "    'sm': 'top_hty',\n",
    "    'fbm': '0',\n",
    "    'ie': 'utf8',\n",
    "    'query': search_key}\n",
    "res = requests.get(url, params=para ,verify=False)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://finance.naver.com/item/board.nhn?code=005690'\n",
    "res = requests.get(url,verify=False)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.request.headers\n",
    "#request header가 python이라 오류 발생 다른 header로 변경 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://finance.naver.com/item/board.nhn?code=005690'\n",
    "h = {'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "\n",
    "res = requests.get(url,headers=h, verify=False)\n",
    "res.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특정 태그 분석\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://search.naver.com/search.naver'\n",
    "search_key = '아이유'\n",
    "para = {\n",
    "    'where': 'nexearch',\n",
    "    'sm': 'top_hty',\n",
    "    'fbm': '0',\n",
    "    'ie': 'utf8',\n",
    "    'query': search_key}\n",
    "res = requests.get(url, params=para ,verify=False)\n",
    "soup = BeautifulSoup(res.text,\"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# h2.api_title    .은 클래스명을 의미함\n",
    "# h2라는 태그에 api_title이라는 클래스이름을 가진 모든 클래스 검색\n",
    "print(soup.select('h2.api_title')[0])\n",
    "print(soup.select('h2.api_title')[0].text)\n",
    "\n",
    "#text함수는 태그를 제외하고 text만 출력 해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = soup.select('h2.api_title')\n",
    "for result in results:\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버웹툰 인기급상승 인기순 1위 작품 가져오기\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://comic.naver.com/index'\n",
    "res = requests.get(url,verify = False)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "soup.select('li.rank01 > a')[0].text #자식태그 선택 방법        부모태그.classname > 자식태그"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버웹툰 인기급상승 인기순 1~10위 작품 가져오기 (f-포멧팅 사용)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://comic.naver.com/index'\n",
    "res = requests.get(url,verify = False)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "rankes = soup.select('#realTimeRankFavorite a') #id 검색 시 #id이름 \n",
    "ran_num = 0\n",
    "for rank in rankes:\n",
    "    ran_num += 1\n",
    "    print(f'{ran_num}위:' ,rank.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버웹툰 인기급상승 인기순 1~10위 작품 가져오기 (enurmerate 사용)\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://comic.naver.com/index'\n",
    "res = requests.get(url,verify = False)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "ranks = soup.select('#realTimeRankFavorite a') #id 검색 시 #id이름 \n",
    "\n",
    "for i, rank in enumerate(ranks):\n",
    "    print(i+1,\"위:\" , rank.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 140page Requests + BS 실전 연습 1 풀이1\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.naver.com/'\n",
    "res = requests.get(url,verify=False)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "titles = soup.select('div.section_strategy > ul > li > span > a')\n",
    "\n",
    "for title in titles:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 140page Requests + BS 실전 연습 1 풀이2\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://finance.naver.com/'\n",
    "res = requests.get(url,verify=False)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "titles = soup.select('div.section_strategy a') # 자손태그 추출 시 > 기호 사용하지 않아도 됨\n",
    "titles = titles[:-1]\n",
    "\n",
    "for title in titles:\n",
    "    print(title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버 영화 미나리 댓글 내용 가져오기(마지막 댓글 일부 짤림)\n",
    "\n",
    "url = 'https://movie.naver.com/movie/bi/mi/basic.naver?code=187310'\n",
    "res = requests.get(url,verify=False)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "comments = soup.select('div.score_reple > p')\n",
    "\n",
    "for i in comments :\n",
    "    print(i.text.strip()) #str 문자열 dtype에서 공백 지우기 strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버 영화 미나리 댓글 내용 가져오기(마지막 댓글 전체 내용 표시)\n",
    "\n",
    "url = 'https://movie.naver.com/movie/bi/mi/basic.naver?code=187310'\n",
    "res = requests.get(url,verify=False)\n",
    "soup = BeautifulSoup(res.text, 'html.parser')\n",
    "comments = soup.select('div.score_reple > p')\n",
    "\n",
    "for comment in comments:\n",
    "    a = comment.select('a')\n",
    "    if len(a) > 0:\n",
    "        print(a[0].attrs['data-src']) #data-src = data-soruce\n",
    "    else:\n",
    "        print(comment.text.strip()) #str 문자열 dtype에서 공백 지우기 strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인베스팅닷컴 철광석 정보 추출\n",
    "#6개월 정보 추출을 위해 url 추출이 매우 중요\n",
    "#주소창에서 url 복사 시 6개월치 정보 추출 불가\n",
    "# network - Doc - Preview를 이용해 확인 시 없으면 Fetch/XHR 들어가서 확인 해보기\n",
    "# dictionay 자료 형은 json?\n",
    "\n",
    "url = 'https://api.investing.com/api/financialdata/961729/historical/chart/'\n",
    "p = {\n",
    "        'period': 'P6M',\n",
    "        'interval': 'P1D',\n",
    "        'pointscount': '120'}\n",
    "h = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36'}\n",
    "res = requests.get(url,params = p,headers=h ,verify=False)\n",
    "#soup = BeautifulSoup(res.text, 'html.parser') <-html 형태가 아니므로 필요 없음\n",
    "json_data = res.json()\n",
    "datas =json_data['data']\n",
    "for i in datas :\n",
    "        print(i)\n",
    "        print('날짜', i[0]/1000)\n",
    "        print('가격', i[1])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#인베스팅닷컴 철광석 정보 추출 - 날짜 변환\n",
    "#날짜변환 타임스탬프 참고 https://ko.rakko.tools/tools/29/\n",
    "import datetime\n",
    "datas = json_data['data']\n",
    "\n",
    "results = []\n",
    "for data in datas:\n",
    "    ymd = str(datetime.datetime.fromtimestamp(data[0]/1000))\n",
    "    ymd = ymd[:10]\n",
    "    info = {'날짜': ymd, '가격':data[1]}\n",
    "    results.append(info)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel('엑셀이름.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#휘발유 일별시세 추출\n",
    "url = 'https://finance.naver.com/marketindex/oilDailyQuote.naver'\n",
    "results = []\n",
    "for i in range(1,11):\n",
    "    p = {'marketindexCd': 'OIL_GSL','page': i}\n",
    "    res = requests.get(url,params=p,verify=False)\n",
    "    soup = BeautifulSoup(res.text,'html.parser')\n",
    "    price = soup.select('.tbl_exchange.today') #class가 tbl_exchange와 today 두개이므로 .으로 구분하고 동시에 class 2개 select\n",
    "    price = str(price)\n",
    "    df = pd.read_html(price)\n",
    "    results.append(df[0]) #df가 아닌 df[0]인 이유? DataFrame 유형으로 가져오기 위해\n",
    "\n",
    "df_results = pd.concat(results,ignore_index=True)\n",
    "df_results\n",
    "df_results.to_excel('휘발유가격.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#철강백과사전 내 용어 및 의미 엑셀 추출\n",
    "\n",
    "url = 'https://terms.naver.com/list.naver'\n",
    "base_url = 'https://terms.naver.com'\n",
    "\n",
    "for i in range(1,2):\n",
    "    p = {\n",
    "    'cid': '67995',\n",
    "    'categoryId': '67995',\n",
    "    'page': i}\n",
    "    results = []\n",
    "    res = requests.get(url,params=p,verify=False)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    subjects_link = soup.select('strong.title > a:nth-child(1)') #nth-child() 특정 자식만 가져오기 \n",
    "    subjects_link = subjects_link[1:]\n",
    "    \n",
    "\n",
    "    for j in subjects_link:\n",
    "        sub_url = j.attrs['href']\n",
    "        full_url = base_url+sub_url\n",
    "        res = requests.get(full_url,verify=False)\n",
    "        soup = BeautifulSoup(res.text, 'html.parser')\n",
    "        title = soup.select('h2.headword')[0].text\n",
    "        mean = soup.select('#size_ct .txt')\n",
    "        allmean = []\n",
    "        for k in range(len(mean)):\n",
    "            allmean.append(mean[k].text)\n",
    "        info = {'용어':title, '의미':''.join(allmean)} #의미 value값이 List인 경우 []형태로 보기 불편하므로 join 사용       \n",
    "        results.append(info)\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel('철강백과사전.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Payload\n",
    "\n",
    "get -> params\n",
    "\n",
    "post -> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pw = pg.password(text='비밀번호입력')\n",
    "url = 'https://www.dataq.or.kr/www/accounts/login/proc.do'\n",
    "d = {\n",
    "    'userperm': 'S01',\n",
    "    'loginid': 'kttu0008',\n",
    "    'loginpw': pw,}\n",
    "\n",
    "#로그인 상태를 유지 시켜 줄 session  생성 필요\n",
    "s = requests.session()\n",
    "res = requests.post(url,data=d, verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#쿠키를 이용한 로그인 상태 유지\n",
    "\n",
    "url = 'https://apis.naver.com/cafe-home-web/cafe-home/v1/homepc?myCafeCount=10&articleCount=3&useMyCafeEvent=true'\n",
    "p = {\n",
    "    'myCafeCount': '10',\n",
    "    'articleCount': '3',\n",
    "    'useMyCafeEvent': 'true'\n",
    "}\n",
    "# c쿠키\n",
    "# c = {  NNB=CNVIUS7BZCHGE; nx_ssl=2; page_uid=hqYnTspwJh4ssCD2U+RsssssstC-273934; nid_inf=1718696977; NID_AUT=b2yw/wkXbGu9ZykmWHE39kzCofnceTELISPwbU7IRr5U+bHS6NmvQdawcoe40QNV; NID_JKL=yfpjMBhhAlpD5l2KdcspiyPa/SwqvKTD1c0xfjLc1ac=; NID_SES=AAAByJLRBnkwK+M40GBYMFJ52PudF7P/0eaNATSGX82KU02mea8IukABWX9DBt+s84wHXcEe+QyBYEt/v0ftfabik6jrsuYeqdzht4mdGMpgt/7aW+kBl5bdgaxjzv7E+yQ0W+Pjypep5CDzg2GrDjI5jviRj+FFFCBSrv0HSCOzUZhrOEtp6HsmcjHqwOzkeSwWnAxI9U3jXSsqx19h586phyY8yyFb39e4g8AUlD/LswIAKRlDkGAOWbMY/hv5juN3lWkTsgkOHulS1w/V1zhCK8Lz6s1629rx2xZxjorbW1bNOWHotvCu/6wp9cI7BFsZBuSjmOS+9ja8Q3ApZm7bHjASZ/vcpMXtbHBvmDnAPi9NP4YQQA00CDw8Q9E3SfMc01JZN8H/k4w7z+xfYS2Z+ND4BgKHt0MlePQzv9I42onAQEErZ2LmBQ41nbnqGP2zHW2gFHivBLaU2D0GNfM0Kn3egmNR1/LKq+8UP++F/7qN8b//lIHX6J+rBp/u8YSAOjkm02r3JPRLQufMtc3j/F0EQq2SXfwRayHzQLyVHkkeC9ZH0RSZLWlSCqRxDIeq/ndFFRbBEF2KfQyUT4AgzfFHB6B3rqt7IsEsWhQgkuoz\n",
    "\n",
    "\n",
    "\n",
    "res=requests.get(url,verify=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome('../chromedriver')\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.naver.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome('../chromedriver')\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.naver.com')\n",
    "\n",
    "#아이유 검색창 입력\n",
    "driver.find_element(By.CSS_SELECTOR, \"#query\").send_keys('아이유') #아이디 명이므로 #을 붙여서 입력\n",
    "\n",
    "#검색버튼 클릭\n",
    "driver.find_element(By.CSS_SELECTOR, '#search_btn').click()\n",
    "\n",
    "#뉴스탭 클릭\n",
    "selector = '#lnb > div.lnb_group > div > ul > li:nth-child(3) > a' #우클릭 - copy selector\n",
    "driver.find_element(By.CSS_SELECTOR, selector).click()\n",
    "\n",
    "#뉴스 제목 가져오기\n",
    "titles= driver.find_elements(By.CSS_SELECTOR, '.news_tit')\n",
    "for title in titles:\n",
    "    print(title.text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "driver = webdriver.Chrome('../chromedriver')\n",
    "driver.maximize_window()\n",
    "driver.get('https://www.naver.com')\n",
    "\n",
    "driver.find_element(By.CSS_SELECTOR, '#NM_FAVORITE > div.group_nav > ul.list_nav.NM_FAVORITE_LIST > li:nth-child(8) > a').click()\n",
    "\n",
    "ranks = driver.find_elements(By.CSS_SELECTOR, '#realTimeRankFavorite > li.rank01 > a')\n",
    "i = 0\n",
    "for rank in ranks:\n",
    "    i += 1\n",
    "    print(f'{i}위 : ',rank.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#종합실습2\n",
    "\n",
    "results = []\n",
    "name = []\n",
    "address = []\n",
    "\n",
    "url = 'https://im.diningcode.com/API/isearch/'\n",
    "for num in range(1,6):\n",
    "    d = {\n",
    "        'dc_flag': '1',\n",
    "        'mode': 'poi',\n",
    "        'order': 'r_score',\n",
    "        'page': num,\n",
    "        'query': '포항',\n",
    "        'rn_search_flag': 'on',\n",
    "        'search_type': 'poi_search',\n",
    "        'size': '20',\n",
    "        \n",
    "    }\n",
    "    res = requests.post(url, data = d , verify=False)\n",
    "    jd= res.json()\n",
    "    jd2 = jd['result_data']['poi_section']['list']\n",
    "\n",
    "    for i in range(0, len(jd2)):\n",
    "        name = jd2[i]['nm']\n",
    "        address = jd2[i]['addr']\n",
    "        info = {'식당이름':name, '주소':address}\n",
    "        results.append(info)\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(results)\n",
    "df.to_excel('포항맛집.xlsx')\n",
    "   \n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f83d677db8bd35d2fb0873f2db9b473d98cd1a0194512a81b941b3e6839d6f79"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
